# Setup {#intro}

## Navigate R markdown quickly 

* When you want to quickly find a bit if your code to edit instead of scrolling up and down your R Markdown code jump quickly to the right bit using the document outline. You can show the outline in one of three ways:

1. Hold down Ctrl+Shift+O. 
2. Click the top right icon in the code pane.
3. Left click on the bottom bar of the R markdown file. 

The gif below shows these three methods. It was recorded with [ScreenToGif](https://www.screentogif.com/). I gave a donation as I found it so easy to use and it includes genuinely useful features like a progress bar and the ability to pixelate out sections of the recording.

```{r, echo=FALSE, out.width = "100%"}
knitr::include_graphics("outline.gif") 
```

## Rstudio shortcuts

* Another tip to speed up coding in RStudio is to use shortcuts. Here is the full list of [RStudio shorcuts](https://support.rstudio.com/hc/en-us/articles/200711853-Keyboard-Shortcuts).

* I use Ctrl+Shift+M in Windows (Cmd+Shift+M in Mac) to insert a pipe (%>%) with spaces. This makes tidyverse coding fast.

* I also use Alt+- in Windows (Option+- in Mac) to create the assign operator (<-).

## Load R packages to your library

Here are all the R packages used in this book. 

```{r libraries, echo=TRUE,message=FALSE,warning=FALSE,results='hide'}
# data vis https://www.htmlwidgets.org/index.html
library(ggplot2) # static charts - amazing variety
library(plotly) # interactive charts
library(apexcharter) # much like the paid for highchater js library. Powerful
library(trelliscopejs) #  small multiples
library(dygraphs) # awesome interactive timeseries

# ggplot extensions https://www.ggplot2-exts.org/gallery/
library(scales) # improve your scales
library(gganimate) # animate your ggplot
library(png) # 
library(directlabels) # for directly labelling lines for example
library(gghighlight) # label points of interest on your charts
library(ggrepel) # move labels so they don't overlap
library(glue) # 

# colours
library(RColorBrewer) # ready to use colour pallets
library(prismatic) # palettes and ways to tweak an entier pallete

# tables
library(kableExtra) # attractive static tables
library(formattable) # colour tables. Like Excel's conditional formattinng
library(rpivotTable) # like Excel's pivot table
library(DT) # awesome interactive tables

# Quality Assurance
library(tidylog) # great for QA on the fly 

# wrangling / munging / manipulating
library(tidyverse) # loads of useful packages in one 

library(crosstalk) # link html widgets like plotly to DT tables

# time series tools
library(anytime) # convert text into the right date type
library(tsbox) # convert to time series for dygraphs

# sample data
library(mosaicData) # sample data
```

## The data to visualise

* Often in EDA and data visualisation we are most interested in values changing over time. For example, are things getting worse, better, higher, lower etc...For this reason, instead of using a [built in data set](https://stat.ethz.ch/R-manual/R-devel/library/datasets/html/00Index.html) like iris or mtcars we mostly use the [Texas housing sales ](http://vincentarelbundock.github.io/Rdatasets/doc/ggplot2/txhousing.html) data in this book. This is a time series data set built into ggplot.

* To improve your own skills I recommend finding other open data sets to develop your data vis skills. I found the marriage data we look at later in this carefully curated and [comprehensive list of R datasets](https://vincentarelbundock.github.io/Rdatasets/). The [Tidy Tuesday](https://github.com/rfordatascience/tidytuesday) data sets are also a great source where you also get to learn from seeing how others (including David Robinson) have tackled them. Finally, look for data or stories that interest you. I recently saw a data visualisation in The Times newspaper on [smoking vs vaping](https://github.com/billster45/improve_a_data_viz/blob/master/README.md) that I thought I could improve.

* The only manipulation we will do to the Texas housing sales data is to create a real date using [lubridate](https://lubridate.tidyverse.org/). 

* We'll also use [tidylog](https://github.com/elbersb/tidylog/blob/master/README.md) with dplyr. Tidylog is an easy way to include fast basic Quality Assurance while you code. Just replace the dplyr verbs with the same verb in tidylog. The tidylog version tells you what each dplyr verb has done to your data. For example, how many rows are dropped or added by filters and joins, or what percentage of values have changed after a mutate.

```{r create_df, message=TRUE}
# create a data frame with a real date for plotting
df <- ggplot2::txhousing %>% 
  tidylog::mutate(date = lubridate::make_date(year = year,
                                              month = month, 
                                              day =1)) 
```

* Let's also create a data frame with fewer cities so that some plots we draw later are less crowded. Here we select only cities where the maximum number of sales in any month is 800 or more.

```{r}
# reduce the number of cities for simpler plots
df_red <- df %>% 
  dplyr::group_by(city) %>% 
  tidylog::mutate(sales_max = base::max(sales)) %>% 
  dplyr::ungroup() %>% 
  tidylog::filter(sales_max >= 500)
```

* Hold on. Look! Read the tidylog messages above. It tells us the percentage of values that are "NA" is 43% ("new variable 'sales_max' with 27 unique values and 43% NA"). Well spotted tidylog. We correct it below by removing NAs from the maximum sales value using **na.rm = TRUE**.

```{r}
# reduce the number of cities for simpler plots
df_red <- df %>% 
  dplyr::group_by(city) %>% 
  tidylog::mutate(sales_max = base::max(sales, 
                                        na.rm = TRUE)) %>% 
  dplyr::ungroup() %>% 
  tidylog::filter(sales_max >= 500)
```

* We know the code above has been corrected as its tidylog message now tells us that the new variable 'sales_max' has 0% NA as we would expect.

* Let's also look at the top few rows of the data frame we created using a kableExtra table. The [Tables] chapter later on in this book describes different table methods in more detail.

```{r}
kableExtra::kable(utils::head(df))
```

## Code style 

### Rule 1: Add package names to all functions

* Use the package name before every function to make your code easier to read, even for [base R](https://rstudio.com/wp-content/uploads/2016/05/base-r.pdf) functions. 

* When I started learning R I tried to do it using other people's code. But I got confused where functions came from. Particularly when they had used lots of different packages mixed with base functions and their own functions. It made their code appear more complex and intimidating than it should have.

* Another benefit of typing the package name before each function is you can hit the tab key at the end of the double colon. From here you can browse all the functions in that package that appear as a scrollable list.

> ggplot2::

* Also, try highlighting a function and its package name then hit the F1 key to see the help pages for that particular function. While hitting the F2 key can be a quick way to see all the possible arguments in a function including the default values the author of the package has chosen you might not be aware of. 

## Rule 2: Add argument names to all functions

* Finally, instead of relying on the order of the arguments that the function expects, name every argument you set. Your code will be quicker to understand when we know exactly what arguments are being set without having to read the help page for that function.

```{r, echo=FALSE, out.width = "1100%"}
knitr::include_graphics("package_name.gif") 
```

### Rule 3: One line does one thing

* Ideally one line of code does one thing. Hit the return key after every pipe (%>%), comma, or plus (+) and RStudio tabs will space your code out in just the right way.

* For example, the code below works but doesn't follow the rules 1 to 3. The code is cramped, slow to understand, and can be difficult edit or re-use.

```{r cramped_code, eval=FALSE}
ggplot(df) +
  geom_line(aes(date, sales, colour = city)) +
  ggplot2::theme_minimal() +
  gghighlight(max(sales) > 5000, label_params = list(size = 4)) +
  scale_y_continuous(labels = scales::comma) +
  scale_x_date(date_breaks = "1 year", labels = scales::date_format("%d %b %y"), limits = c(as.Date("2000-01-01"), as.Date("2015-07-01"))) +
  labs(title = "US Housing Sales over time", subtitle = "US cities with more than 5k sales in a month", caption = "Source: ggplot2 package demo data") +
  geom_vline(xintercept = years, linetype = 4) +
  theme(panel.grid.major.x = element_blank(), panel.grid.minor.x = element_blank(), strip.text.x = element_text(size = 10), axis.text.x = element_text(angle = 60, hjust = 1, size = 9), legend.text = element_text(size = 12), legend.position = "right", legend.direction = "vertical", plot.title = element_text(size = 22, face = "bold"), plot.subtitle = element_text(color = "grey", size = 18), plot.caption = element_text(hjust = 0, size = 12, color = "darkgrey"), legend.title = element_blank())
```

* In contrast, the code below is the identical to the code above but it follows the 3 rules. The benefits of following these rules are that you can more easily:

1. Run your code top downwards in chunks adding more lines each time (like the popular ggplot flip-books I describe at bullet 11 in my collection of [R guides and galleries](https://github.com/billster45/r-guides-and-galleries/blob/master/README.md#learn-to-visualise-data-with-r)
2. Comment out whole lines of code or parameters in a function to understand what they are doing.
3. Find and edit arguments in a function (e.g. a font size)
4. Help others QA or re-use your code more quickly.
5. Help others new to R understand what you are doing and learn faster.
6. Avoid being a "gatekeeper" of your R knowledge and skills. Share, explain and democratise what you know. You can then move on to more complex analysis in R with an even higher value (as proposed by Richard Susskind in [The Future of Professions](https://www.amazon.co.uk/dp/0198713398/)).

* Further tweaks to improve code clarity are to put spaces either side of the equals sign and to use use [styler](https://styler.r-lib.org/) to automatically apply some of these rules. You can also [customise styler](https://cran.r-project.org/web/packages/styler/vignettes/customizing_styler.html) to apply your own rules. I would like to try customising styler to apply rules 1 to 3 above.

```{r clean_code, eval=FALSE}
df %>%
  ggplot2::ggplot() +
  ggplot2::aes(
    x = date,
    y = sales,
    colour = city
  ) +
  ggplot2::geom_line() +
  ggplot2::theme_minimal() +
  gghighlight::gghighlight(max(sales) > 5000,
                           label_params = list(size = 4)
  ) +
  ggplot2::scale_y_continuous(labels = scales::comma) +
  ggplot2::scale_x_date(
    date_breaks = "1 year",
    labels = scales::date_format("%d %b %y"),
    limits = c(
      as.Date("2000-01-01"),
      as.Date("2015-07-01")
    )
  ) +
  ggplot2::labs(
    title = "US Housing Sales over time",
    subtitle = "US cities with more than 5k sales in a month",
    caption = "Source: ggplot2 package demo data"
  ) +
  ggplot2::geom_vline(
    xintercept = years,
    linetype = 4
  ) +
  ggplot2::theme(
    panel.grid.major.x = element_blank(),
    panel.grid.minor.x = element_blank(),
    strip.text.x = element_text(size = 10),
    axis.text.x = element_text(
      angle = 60,
      hjust = 1,
      size = 9
    ),
    legend.text = element_text(size = 12),
    legend.position = "right",
    legend.direction = "vertical",
    plot.title = element_text(
      size = 22,
      face = "bold"
    ),
    plot.subtitle = element_text(
      color = "grey",
      size = 18
    ),
    plot.caption = element_text(
      hjust = 0,
      size = 12,
      color = "darkgrey"
    ),
    legend.title = element_blank()
  )
```

* Note this layout differs from the [layered gramar of graphics](https://r4ds.had.co.nz/data-visualisation.html#the-layered-grammar-of-graphics) code template below.

```{r, eval = FALSE}
ggplot(data = <DATA>) + 
  <GEOM_FUNCTION>(
     mapping = aes(<MAPPINGS>),
     stat = <STAT>, 
     position = <POSITION>
  ) +
  <COORDINATE_FUNCTION> +
  <FACET_FUNCTION>
```

* My preference is to mentally view this as data being poured into ggplot through the pipe, then we tell it which columns to map, then the geom, followed by the same co-ordinate and facet function as Wickham recommends. 

* This is inspired by the code layout of the many flipbook guides I describe at bullet 11 [here](https://github.com/billster45/r-guides-and-galleries/blob/master/README.md#learn-to-visualise-data-with-r).

```{r, eval=FALSE}
<DATA> %>% 
  ggplot2::ggplot() + 
  ggplot2::aes(<MAPPINGS>) +
  ggplot2::<GEOM_FUNCTION>(
     stat = <STAT>, 
     position = <POSITION>
  ) +
  <COORDINATE_FUNCTION> +
  <FACET_FUNCTION>
```